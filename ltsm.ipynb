{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8eb0896a",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ea42af73",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Starting LSTM Experiments\n",
            "Datasets: 10\n",
            "Runs per dataset: 15\n",
            "Max epochs: 200 (patience=30)\n",
            "============================================================\n",
            "\n",
            "\n",
            "############################################################\n",
            "DATASET: CARSALES\n",
            "############################################################\n",
            "[CARSALES] Using columns - SERIE: idx=1 (SERIE), SPLIT: idx=2 (SPLIT)\n",
            "  Row 2: SERIE=0.0478301105645122, SPLIT=Treinamento\n",
            "  Row 3: SERIE=0.15391359407724903, SPLIT=Treinamento\n",
            "  Row 4: SERIE=0.3145487311869855, SPLIT=Treinamento\n",
            "[CARSALES] Data loaded: n=108, range=[0.00e+00, 1.00e+00], mean=4.40e-01\n",
            "[CARSALES] Splits: Train=52, Val=36, Test=20\n",
            "CARSALES - Run 1/15 - Test MSE: 1.171140e-01, RMSE: 3.422192e-01\n",
            "CARSALES - Run 2/15 - Test MSE: 1.250256e-01, RMSE: 3.535896e-01\n",
            "CARSALES - Run 3/15 - Test MSE: 1.342031e-01, RMSE: 3.663374e-01\n",
            "CARSALES - Run 4/15 - Test MSE: 1.336758e-01, RMSE: 3.656170e-01\n",
            "CARSALES - Run 5/15 - Test MSE: 1.390806e-01, RMSE: 3.729352e-01\n",
            "CARSALES - Run 6/15 - Test MSE: 1.141951e-01, RMSE: 3.379276e-01\n",
            "CARSALES - Run 7/15 - Test MSE: 1.317539e-01, RMSE: 3.629792e-01\n",
            "CARSALES - Run 8/15 - Test MSE: 1.185366e-01, RMSE: 3.442914e-01\n",
            "CARSALES - Run 9/15 - Test MSE: 1.253181e-01, RMSE: 3.540030e-01\n",
            "CARSALES - Run 10/15 - Test MSE: 1.313237e-01, RMSE: 3.623862e-01\n",
            "CARSALES - Run 11/15 - Test MSE: 1.349482e-01, RMSE: 3.673529e-01\n",
            "CARSALES - Run 12/15 - Test MSE: 1.298327e-01, RMSE: 3.603230e-01\n",
            "CARSALES - Run 13/15 - Test MSE: 1.165069e-01, RMSE: 3.413311e-01\n",
            "CARSALES - Run 14/15 - Test MSE: 1.084386e-01, RMSE: 3.293002e-01\n",
            "CARSALES - Run 15/15 - Test MSE: 1.219089e-01, RMSE: 3.491545e-01\n",
            "\n",
            "CARSALES Summary:\n",
            "Test MSE:  1.254575e-01 ± 8.717030e-03\n",
            "Test RMSE: 3.539832e-01 ± 1.238422e-02\n",
            "\n",
            "\n",
            "############################################################\n",
            "DATASET: Electricity\n",
            "############################################################\n",
            "[Electricity] Using columns - SERIE: idx=1 (SERIE), SPLIT: idx=2 (SPLIT)\n",
            "  Row 2: SERIE=0.05433884297520661, SPLIT=Treinamento\n",
            "  Row 3: SERIE=0.03384297520661157, SPLIT=Treinamento\n",
            "  Row 4: SERIE=0.02371900826446281, SPLIT=Treinamento\n",
            "[Electricity] Data loaded: n=486, range=[0.00e+00, 4.13e+10], mean=8.50e+07\n",
            "[Electricity] Splits: Train=252, Val=169, Test=65\n",
            "[Electricity] WARNING: Found 1 corrupted values > 10.0\n",
            "  Outlier indices: [3]\n",
            "  Outlier values: [4.1322314e+10]\n",
            "  Replaced index 3 (value=4.56e-02) with median=0.0456\n",
            "[Electricity] Fixed! New range: [0.00e+00, 1.00e+00]\n",
            "Electricity - Run 1/15 - Test MSE: 2.015555e-02, RMSE: 1.419702e-01\n",
            "Electricity - Run 2/15 - Test MSE: 2.400057e-02, RMSE: 1.549212e-01\n",
            "Electricity - Run 3/15 - Test MSE: 2.233937e-02, RMSE: 1.494636e-01\n",
            "Electricity - Run 4/15 - Test MSE: 2.017855e-02, RMSE: 1.420512e-01\n",
            "Electricity - Run 5/15 - Test MSE: 2.703409e-02, RMSE: 1.644205e-01\n",
            "Electricity - Run 6/15 - Test MSE: 2.549595e-02, RMSE: 1.596745e-01\n",
            "Electricity - Run 7/15 - Test MSE: 2.856823e-02, RMSE: 1.690214e-01\n",
            "Electricity - Run 8/15 - Test MSE: 1.383926e-02, RMSE: 1.176404e-01\n",
            "Electricity - Run 9/15 - Test MSE: 1.712412e-02, RMSE: 1.308592e-01\n",
            "Electricity - Run 10/15 - Test MSE: 2.542895e-02, RMSE: 1.594646e-01\n",
            "Electricity - Run 11/15 - Test MSE: 2.700955e-02, RMSE: 1.643458e-01\n",
            "Electricity - Run 12/15 - Test MSE: 1.685603e-02, RMSE: 1.298308e-01\n",
            "Electricity - Run 13/15 - Test MSE: 2.292366e-02, RMSE: 1.514056e-01\n",
            "Electricity - Run 14/15 - Test MSE: 2.038024e-02, RMSE: 1.427594e-01\n",
            "Electricity - Run 15/15 - Test MSE: 2.803703e-02, RMSE: 1.674426e-01\n",
            "\n",
            "Electricity Summary:\n",
            "Test MSE:  2.262474e-02 ± 4.315060e-03\n",
            "Test RMSE: 1.496847e-01 ± 1.480625e-02\n",
            "\n",
            "\n",
            "############################################################\n",
            "DATASET: GAS\n",
            "############################################################\n",
            "[GAS] Using columns - SERIE: idx=1 (SERIE), SPLIT: idx=2 (SPLIT)\n",
            "  Row 2: SERIE=0.004762524552145207, SPLIT=Treinamento\n",
            "  Row 3: SERIE=0.0, SPLIT=Treinamento\n",
            "  Row 4: SERIE=0.0565113472324112, SPLIT=Treinamento\n",
            "[GAS] Data loaded: n=192, range=[0.00e+00, 1.00e+00], mean=4.45e-01\n",
            "[GAS] Splits: Train=106, Val=72, Test=14\n",
            "GAS - Run 1/15 - Test MSE: 2.992763e-02, RMSE: 1.729960e-01\n",
            "GAS - Run 2/15 - Test MSE: 2.154126e-02, RMSE: 1.467694e-01\n",
            "GAS - Run 3/15 - Test MSE: 1.462660e-02, RMSE: 1.209405e-01\n",
            "GAS - Run 4/15 - Test MSE: 2.945008e-03, RMSE: 5.426793e-02\n",
            "GAS - Run 5/15 - Test MSE: 3.321466e-03, RMSE: 5.763216e-02\n",
            "GAS - Run 6/15 - Test MSE: 7.758270e-03, RMSE: 8.808104e-02\n",
            "GAS - Run 7/15 - Test MSE: 2.081767e-02, RMSE: 1.442833e-01\n",
            "GAS - Run 8/15 - Test MSE: 2.690812e-02, RMSE: 1.640370e-01\n",
            "GAS - Run 9/15 - Test MSE: 1.908020e-02, RMSE: 1.381311e-01\n",
            "GAS - Run 10/15 - Test MSE: 1.697322e-02, RMSE: 1.302813e-01\n",
            "GAS - Run 11/15 - Test MSE: 2.660396e-02, RMSE: 1.631072e-01\n",
            "GAS - Run 12/15 - Test MSE: 1.541266e-02, RMSE: 1.241477e-01\n",
            "GAS - Run 13/15 - Test MSE: 3.420957e-02, RMSE: 1.849583e-01\n",
            "GAS - Run 14/15 - Test MSE: 2.496614e-02, RMSE: 1.580068e-01\n",
            "GAS - Run 15/15 - Test MSE: 2.189808e-02, RMSE: 1.479800e-01\n",
            "\n",
            "GAS Summary:\n",
            "Test MSE:  1.913266e-02 ± 8.909396e-03\n",
            "Test RMSE: 1.330413e-01 ± 3.785057e-02\n",
            "\n",
            "\n",
            "############################################################\n",
            "DATASET: LAKEERIE\n",
            "############################################################\n",
            "[LAKEERIE] Using columns - SERIE: idx=1 (SERIE), SPLIT: idx=2 (SPLIT)\n",
            "  Row 2: SERIE=0.4763, SPLIT=Treinamento\n",
            "  Row 3: SERIE=0.4648999999999999, SPLIT=Treinamento\n",
            "  Row 4: SERIE=0.5085000000000001, SPLIT=Treinamento\n",
            "[LAKEERIE] Data loaded: n=600, range=[0.00e+00, 1.00e+00], mean=4.99e-01\n",
            "[LAKEERIE] Splits: Train=300, Val=200, Test=100\n",
            "LAKEERIE - Run 1/15 - Test MSE: 1.548356e-03, RMSE: 3.934915e-02\n",
            "LAKEERIE - Run 2/15 - Test MSE: 1.582545e-03, RMSE: 3.978121e-02\n",
            "LAKEERIE - Run 3/15 - Test MSE: 1.938163e-03, RMSE: 4.402458e-02\n",
            "LAKEERIE - Run 4/15 - Test MSE: 1.524372e-03, RMSE: 3.904321e-02\n",
            "LAKEERIE - Run 5/15 - Test MSE: 1.496510e-03, RMSE: 3.868475e-02\n",
            "LAKEERIE - Run 6/15 - Test MSE: 1.651744e-03, RMSE: 4.064165e-02\n",
            "LAKEERIE - Run 7/15 - Test MSE: 1.652167e-03, RMSE: 4.064686e-02\n",
            "LAKEERIE - Run 8/15 - Test MSE: 1.610172e-03, RMSE: 4.012695e-02\n",
            "LAKEERIE - Run 9/15 - Test MSE: 1.557663e-03, RMSE: 3.946724e-02\n",
            "LAKEERIE - Run 10/15 - Test MSE: 1.542666e-03, RMSE: 3.927679e-02\n",
            "LAKEERIE - Run 11/15 - Test MSE: 2.529737e-03, RMSE: 5.029649e-02\n",
            "LAKEERIE - Run 12/15 - Test MSE: 1.960201e-03, RMSE: 4.427416e-02\n",
            "LAKEERIE - Run 13/15 - Test MSE: 1.548342e-03, RMSE: 3.934898e-02\n",
            "LAKEERIE - Run 14/15 - Test MSE: 1.549775e-03, RMSE: 3.936718e-02\n",
            "LAKEERIE - Run 15/15 - Test MSE: 1.740934e-03, RMSE: 4.172450e-02\n",
            "\n",
            "LAKEERIE Summary:\n",
            "Test MSE:  1.695556e-03 ± 2.616080e-04\n",
            "Test RMSE: 4.107025e-02 ± 2.965019e-03\n",
            "\n",
            "\n",
            "############################################################\n",
            "DATASET: Nordic\n",
            "############################################################\n",
            "[Nordic] Using columns - SERIE: idx=1 (SERIE), SPLIT: idx=2 (SPLIT)\n",
            "  Row 2: SERIE=0.357677560708417, SPLIT=Treinamento\n",
            "  Row 3: SERIE=0.3263100237356217, SPLIT=Treinamento\n",
            "  Row 4: SERIE=0.30009129085265657, SPLIT=Treinamento\n",
            "[Nordic] Data loaded: n=3121, range=[0.00e+00, 1.00e+00], mean=5.05e-01\n",
            "[Nordic] Splits: Train=1512, Val=1009, Test=600\n",
            "Nordic - Run 1/15 - Test MSE: 6.681737e-04, RMSE: 2.584906e-02\n",
            "Nordic - Run 2/15 - Test MSE: 2.374877e-03, RMSE: 4.873271e-02\n",
            "Nordic - Run 3/15 - Test MSE: 1.687880e-03, RMSE: 4.108382e-02\n",
            "Nordic - Run 4/15 - Test MSE: 1.354304e-03, RMSE: 3.680087e-02\n",
            "Nordic - Run 5/15 - Test MSE: 7.988716e-04, RMSE: 2.826432e-02\n",
            "Nordic - Run 6/15 - Test MSE: 8.125140e-04, RMSE: 2.850463e-02\n",
            "Nordic - Run 7/15 - Test MSE: 7.273196e-04, RMSE: 2.696886e-02\n",
            "Nordic - Run 8/15 - Test MSE: 8.749222e-04, RMSE: 2.957908e-02\n",
            "Nordic - Run 9/15 - Test MSE: 1.343925e-03, RMSE: 3.665959e-02\n",
            "Nordic - Run 10/15 - Test MSE: 7.577403e-04, RMSE: 2.752708e-02\n",
            "Nordic - Run 11/15 - Test MSE: 6.396679e-04, RMSE: 2.529166e-02\n",
            "Nordic - Run 12/15 - Test MSE: 6.414519e-04, RMSE: 2.532690e-02\n",
            "Nordic - Run 13/15 - Test MSE: 7.495343e-04, RMSE: 2.737762e-02\n",
            "Nordic - Run 14/15 - Test MSE: 8.476557e-04, RMSE: 2.911453e-02\n",
            "Nordic - Run 15/15 - Test MSE: 1.097166e-03, RMSE: 3.312350e-02\n",
            "\n",
            "Nordic Summary:\n",
            "Test MSE:  1.025067e-03 ± 4.680482e-04\n",
            "Test RMSE: 3.134695e-02 ± 6.514273e-03\n",
            "\n",
            "\n",
            "############################################################\n",
            "DATASET: PIGS\n",
            "############################################################\n",
            "[PIGS] Using columns - SERIE: idx=1 (SERIE), SPLIT: idx=2 (SPLIT)\n",
            "  Row 2: SERIE=0.4924633013173292, SPLIT=Treinamento\n",
            "  Row 3: SERIE=0.44112569660877526, SPLIT=Treinamento\n",
            "  Row 4: SERIE=0.0, SPLIT=Treinamento\n",
            "[PIGS] Data loaded: n=188, range=[0.00e+00, 1.00e+00], mean=6.58e-01\n",
            "[PIGS] Splits: Train=91, Val=62, Test=35\n",
            "PIGS - Run 1/15 - Test MSE: 1.306345e-02, RMSE: 1.142954e-01\n",
            "PIGS - Run 2/15 - Test MSE: 1.277751e-02, RMSE: 1.130376e-01\n",
            "PIGS - Run 3/15 - Test MSE: 1.372077e-02, RMSE: 1.171357e-01\n",
            "PIGS - Run 4/15 - Test MSE: 1.314578e-02, RMSE: 1.146551e-01\n",
            "PIGS - Run 5/15 - Test MSE: 1.544963e-02, RMSE: 1.242965e-01\n",
            "PIGS - Run 6/15 - Test MSE: 1.309492e-02, RMSE: 1.144331e-01\n",
            "PIGS - Run 7/15 - Test MSE: 1.454957e-02, RMSE: 1.206216e-01\n",
            "PIGS - Run 8/15 - Test MSE: 1.322526e-02, RMSE: 1.150011e-01\n",
            "PIGS - Run 9/15 - Test MSE: 1.703226e-02, RMSE: 1.305077e-01\n",
            "PIGS - Run 10/15 - Test MSE: 1.276414e-02, RMSE: 1.129785e-01\n",
            "PIGS - Run 11/15 - Test MSE: 1.320396e-02, RMSE: 1.149085e-01\n",
            "PIGS - Run 12/15 - Test MSE: 1.335104e-02, RMSE: 1.155467e-01\n",
            "PIGS - Run 13/15 - Test MSE: 1.376620e-02, RMSE: 1.173294e-01\n",
            "PIGS - Run 14/15 - Test MSE: 1.435504e-02, RMSE: 1.198125e-01\n",
            "PIGS - Run 15/15 - Test MSE: 1.322606e-02, RMSE: 1.150046e-01\n",
            "\n",
            "PIGS Summary:\n",
            "Test MSE:  1.378171e-02 ± 1.120827e-03\n",
            "Test RMSE: 1.173043e-01 ± 4.627459e-03\n",
            "\n",
            "\n",
            "############################################################\n",
            "DATASET: POLLUTION\n",
            "############################################################\n",
            "[POLLUTION] Using columns - SERIE: idx=1 (SERIE), SPLIT: idx=2 (SPLIT)\n",
            "  Row 2: SERIE=0.0003217503808389559, SPLIT=Treinamento\n",
            "  Row 3: SERIE=0.0, SPLIT=Treinamento\n",
            "  Row 4: SERIE=0.008043759520973916, SPLIT=Treinamento\n",
            "[POLLUTION] Data loaded: n=130, range=[0.00e+00, 1.00e+00], mean=2.42e-01\n",
            "[POLLUTION] Splits: Train=70, Val=48, Test=12\n",
            "POLLUTION - Run 1/15 - Test MSE: 3.775323e-02, RMSE: 1.943019e-01\n",
            "POLLUTION - Run 2/15 - Test MSE: 3.234718e-02, RMSE: 1.798532e-01\n",
            "POLLUTION - Run 3/15 - Test MSE: 3.429080e-02, RMSE: 1.851777e-01\n",
            "POLLUTION - Run 4/15 - Test MSE: 4.524862e-02, RMSE: 2.127172e-01\n",
            "POLLUTION - Run 5/15 - Test MSE: 4.273964e-02, RMSE: 2.067357e-01\n",
            "POLLUTION - Run 6/15 - Test MSE: 2.849179e-02, RMSE: 1.687951e-01\n",
            "POLLUTION - Run 7/15 - Test MSE: 4.403120e-02, RMSE: 2.098361e-01\n",
            "POLLUTION - Run 8/15 - Test MSE: 2.661463e-02, RMSE: 1.631399e-01\n",
            "POLLUTION - Run 9/15 - Test MSE: 3.714544e-02, RMSE: 1.927315e-01\n",
            "POLLUTION - Run 10/15 - Test MSE: 4.166168e-02, RMSE: 2.041119e-01\n",
            "POLLUTION - Run 11/15 - Test MSE: 4.056937e-02, RMSE: 2.014184e-01\n",
            "POLLUTION - Run 12/15 - Test MSE: 3.515737e-02, RMSE: 1.875030e-01\n",
            "POLLUTION - Run 13/15 - Test MSE: 2.965689e-02, RMSE: 1.722118e-01\n",
            "POLLUTION - Run 14/15 - Test MSE: 3.635428e-02, RMSE: 1.906680e-01\n",
            "POLLUTION - Run 15/15 - Test MSE: 3.642088e-02, RMSE: 1.908426e-01\n",
            "\n",
            "POLLUTION Summary:\n",
            "Test MSE:  3.656553e-02 ± 5.476938e-03\n",
            "Test RMSE: 1.906696e-01 ± 1.451329e-02\n",
            "\n",
            "\n",
            "############################################################\n",
            "DATASET: REDWINE\n",
            "############################################################\n",
            "[REDWINE] Using columns - SERIE: idx=1 (SERIE), SPLIT: idx=2 (SPLIT)\n",
            "  Row 2: SERIE=0.0, SPLIT=Treinamento\n",
            "  Row 3: SERIE=0.061000289100896214, SPLIT=Treinamento\n",
            "  Row 4: SERIE=0.06909511419485401, SPLIT=Treinamento\n",
            "[REDWINE] Data loaded: n=187, range=[0.00e+00, 1.00e+00], mean=3.47e-01\n",
            "[REDWINE] Splits: Train=99, Val=66, Test=22\n",
            "REDWINE - Run 1/15 - Test MSE: 3.524243e-02, RMSE: 1.877297e-01\n",
            "REDWINE - Run 2/15 - Test MSE: 6.780598e-02, RMSE: 2.603958e-01\n",
            "REDWINE - Run 3/15 - Test MSE: 8.914260e-02, RMSE: 2.985676e-01\n",
            "REDWINE - Run 4/15 - Test MSE: 4.891967e-02, RMSE: 2.211779e-01\n",
            "REDWINE - Run 5/15 - Test MSE: 5.087194e-02, RMSE: 2.255481e-01\n",
            "REDWINE - Run 6/15 - Test MSE: 7.261318e-02, RMSE: 2.694683e-01\n",
            "REDWINE - Run 7/15 - Test MSE: 5.034849e-02, RMSE: 2.243847e-01\n",
            "REDWINE - Run 8/15 - Test MSE: 6.762669e-02, RMSE: 2.600513e-01\n",
            "REDWINE - Run 9/15 - Test MSE: 5.456895e-02, RMSE: 2.336000e-01\n",
            "REDWINE - Run 10/15 - Test MSE: 3.517183e-02, RMSE: 1.875415e-01\n",
            "REDWINE - Run 11/15 - Test MSE: 4.239641e-02, RMSE: 2.059039e-01\n",
            "REDWINE - Run 12/15 - Test MSE: 5.914041e-02, RMSE: 2.431880e-01\n",
            "REDWINE - Run 13/15 - Test MSE: 4.206967e-02, RMSE: 2.051089e-01\n",
            "REDWINE - Run 14/15 - Test MSE: 5.930012e-02, RMSE: 2.435162e-01\n",
            "REDWINE - Run 15/15 - Test MSE: 6.507301e-02, RMSE: 2.550941e-01\n",
            "\n",
            "REDWINE Summary:\n",
            "Test MSE:  5.601943e-02 ± 1.439045e-02\n",
            "Test RMSE: 2.347517e-01 ± 3.018357e-02\n",
            "\n",
            "\n",
            "############################################################\n",
            "DATASET: SUNSPOT\n",
            "############################################################\n",
            "[SUNSPOT] Using columns - SERIE: idx=1 (SERIE), SPLIT: idx=2 (SPLIT)\n",
            "  Row 2: SERIE=0.026288117770767616, SPLIT=Treinamento\n",
            "  Row 3: SERIE=0.05783385909568875, SPLIT=Treinamento\n",
            "  Row 4: SERIE=0.08412197686645637, SPLIT=Treinamento\n",
            "[SUNSPOT] Data loaded: n=288, range=[0.00e+00, 1.00e+00], mean=2.55e-01\n",
            "[SUNSPOT] Splits: Train=156, Val=104, Test=28\n",
            "SUNSPOT - Run 1/15 - Test MSE: 1.020488e-02, RMSE: 1.010192e-01\n",
            "SUNSPOT - Run 2/15 - Test MSE: 9.899745e-03, RMSE: 9.949746e-02\n",
            "SUNSPOT - Run 3/15 - Test MSE: 1.114057e-02, RMSE: 1.055489e-01\n",
            "SUNSPOT - Run 4/15 - Test MSE: 1.029571e-02, RMSE: 1.014678e-01\n",
            "SUNSPOT - Run 5/15 - Test MSE: 1.107197e-02, RMSE: 1.052234e-01\n",
            "SUNSPOT - Run 6/15 - Test MSE: 1.047600e-02, RMSE: 1.023523e-01\n",
            "SUNSPOT - Run 7/15 - Test MSE: 9.445309e-03, RMSE: 9.718698e-02\n",
            "SUNSPOT - Run 8/15 - Test MSE: 9.824995e-03, RMSE: 9.912111e-02\n",
            "SUNSPOT - Run 9/15 - Test MSE: 9.022286e-03, RMSE: 9.498572e-02\n",
            "SUNSPOT - Run 10/15 - Test MSE: 1.119777e-02, RMSE: 1.058195e-01\n",
            "SUNSPOT - Run 11/15 - Test MSE: 9.657070e-03, RMSE: 9.827039e-02\n",
            "SUNSPOT - Run 12/15 - Test MSE: 1.037314e-02, RMSE: 1.018486e-01\n",
            "SUNSPOT - Run 13/15 - Test MSE: 9.244942e-03, RMSE: 9.615062e-02\n",
            "SUNSPOT - Run 14/15 - Test MSE: 8.364288e-03, RMSE: 9.145648e-02\n",
            "SUNSPOT - Run 15/15 - Test MSE: 1.054439e-02, RMSE: 1.026859e-01\n",
            "\n",
            "SUNSPOT Summary:\n",
            "Test MSE:  1.005087e-02 ± 7.876126e-04\n",
            "Test RMSE: 1.001756e-01 ± 3.964163e-03\n",
            "\n",
            "\n",
            "############################################################\n",
            "DATASET: B1H\n",
            "############################################################\n",
            "[B1H] Using columns - SERIE: idx=1 (SERIE), SPLIT: idx=2 (SPLIT)\n",
            "  Row 2: SERIE=0.4585139980647426, SPLIT=Treinamento\n",
            "  Row 3: SERIE=0.5174402164486508, SPLIT=Treinamento\n",
            "  Row 4: SERIE=0.5721623567002518, SPLIT=Treinamento\n",
            "[B1H] Data loaded: n=1657, range=[0.00e+00, 1.00e+00], mean=2.96e-01\n",
            "[B1H] Splits: Train=814, Val=543, Test=300\n",
            "B1H - Run 1/15 - Test MSE: 4.390562e-04, RMSE: 2.095367e-02\n",
            "B1H - Run 2/15 - Test MSE: 4.111554e-04, RMSE: 2.027697e-02\n",
            "B1H - Run 3/15 - Test MSE: 4.647376e-04, RMSE: 2.155777e-02\n",
            "B1H - Run 4/15 - Test MSE: 3.553075e-04, RMSE: 1.884960e-02\n",
            "B1H - Run 5/15 - Test MSE: 4.393418e-04, RMSE: 2.096048e-02\n",
            "B1H - Run 6/15 - Test MSE: 4.366578e-04, RMSE: 2.089636e-02\n",
            "B1H - Run 7/15 - Test MSE: 6.981767e-04, RMSE: 2.642303e-02\n",
            "B1H - Run 8/15 - Test MSE: 4.813608e-04, RMSE: 2.193994e-02\n",
            "B1H - Run 9/15 - Test MSE: 5.257225e-04, RMSE: 2.292864e-02\n",
            "B1H - Run 10/15 - Test MSE: 5.021665e-04, RMSE: 2.240907e-02\n",
            "B1H - Run 11/15 - Test MSE: 4.884058e-04, RMSE: 2.209990e-02\n",
            "B1H - Run 12/15 - Test MSE: 4.163506e-04, RMSE: 2.040467e-02\n",
            "B1H - Run 13/15 - Test MSE: 4.736398e-04, RMSE: 2.176327e-02\n",
            "B1H - Run 14/15 - Test MSE: 5.026129e-04, RMSE: 2.241903e-02\n",
            "B1H - Run 15/15 - Test MSE: 5.892773e-04, RMSE: 2.427503e-02\n",
            "\n",
            "B1H Summary:\n",
            "Test MSE:  4.815979e-04 ± 7.852410e-05\n",
            "Test RMSE: 2.187716e-02 ± 1.728497e-03\n",
            "\n",
            "\n",
            "############################################################\n",
            "ALL EXPERIMENTS COMPLETED!\n",
            "Total successful runs: 150\n",
            "Results saved to: results/lstm_results.csv\n",
            "############################################################\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from openpyxl import load_workbook\n",
        "import time\n",
        "import os\n",
        "from typing import Tuple, Dict\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "DEFAULT_CONFIG = {\n",
        "    \"hidden_size\": 128,\n",
        "    \"num_layers\": 2,\n",
        "    \"dropout\": 0.1,\n",
        "    \"lr\": 0.001,\n",
        "    \"lookback\": 10,\n",
        "}\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "MAX_EPOCHS = 200\n",
        "PATIENCE = 30\n",
        "NUM_RUNS = 15\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# REPRODUCIBILITY\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    \"\"\"Seed function for DataLoader workers\"\"\"\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# METRICS\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "def calculate_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
        "    \"\"\"Calculate MSE, RMSE, and R²\"\"\"\n",
        "    mse = np.mean((y_true - y_pred) ** 2)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
        "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "    r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0.0\n",
        "\n",
        "    return {\"mse\": mse, \"rmse\": rmse, \"r2\": r2}\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# DATA LOADING\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "def load_lstm_data_temporal(\n",
        "    dataset_name: str, excel_path: str = \"./datasets/data.xlsx\"\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Load time series data preserving temporal order from Excel\"\"\"\n",
        "\n",
        "    wb = load_workbook(excel_path, read_only=True, data_only=True)\n",
        "\n",
        "    if dataset_name not in wb.sheetnames:\n",
        "        raise ValueError(f\"Dataset '{dataset_name}' not found in workbook\")\n",
        "\n",
        "    ws = wb[dataset_name]\n",
        "\n",
        "    # Read header\n",
        "    header_row = next(ws.iter_rows(min_row=1, max_row=1, values_only=True))\n",
        "    header = [\n",
        "        str(cell).strip().upper() if cell is not None else f\"COL_{i}\"\n",
        "        for i, cell in enumerate(header_row)\n",
        "    ]\n",
        "\n",
        "    # Find SERIE column\n",
        "    serie_col = None\n",
        "    for i, col_name in enumerate(header):\n",
        "        if \"SERIE\" in col_name:\n",
        "            serie_col = i\n",
        "            break\n",
        "\n",
        "    # Find SPLIT column\n",
        "    split_col = None\n",
        "    for i, col_name in enumerate(header):\n",
        "        if \"SPLIT\" in col_name or \"CONJUNTO\" in col_name:\n",
        "            split_col = i\n",
        "            break\n",
        "\n",
        "    if serie_col is None or split_col is None:\n",
        "        raise ValueError(\n",
        "            f\"Could not identify SERIE and SPLIT columns for {dataset_name}\"\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f\"[{dataset_name}] Using columns - SERIE: idx={serie_col} ({header[serie_col]}), SPLIT: idx={split_col} ({header[split_col]})\"\n",
        "    )\n",
        "\n",
        "    # Read data and show first few rows for verification\n",
        "    data = []\n",
        "    for row_idx, row in enumerate(ws.iter_rows(min_row=2, values_only=True)):\n",
        "        if row[serie_col] is not None:\n",
        "            data.append(row)\n",
        "            # Print first 3 data rows to verify correct columns\n",
        "            if row_idx < 3:\n",
        "                print(\n",
        "                    f\"  Row {row_idx+2}: SERIE={row[serie_col]}, SPLIT={row[split_col]}\"\n",
        "                )\n",
        "\n",
        "    if len(data) == 0:\n",
        "        raise ValueError(f\"No data found in sheet '{dataset_name}'\")\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Extract series and split labels\n",
        "    series_data = pd.to_numeric(df.iloc[:, serie_col], errors=\"coerce\").values\n",
        "    split_labels = df.iloc[:, split_col].astype(str).str.strip().values\n",
        "\n",
        "    # Remove NaN values\n",
        "    valid_mask = ~np.isnan(series_data)\n",
        "    series_data = series_data[valid_mask]\n",
        "    split_labels = split_labels[valid_mask]\n",
        "\n",
        "    # Normalize split labels\n",
        "    split_labels_normalized = []\n",
        "    for label in split_labels:\n",
        "        label_lower = label.lower()\n",
        "        if \"treinamento\" in label_lower:\n",
        "            split_labels_normalized.append(\"Treinamento\")\n",
        "        elif \"valida\" in label_lower:\n",
        "            split_labels_normalized.append(\"Validacao\")\n",
        "        elif \"teste\" in label_lower:\n",
        "            split_labels_normalized.append(\"Teste\")\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown split label: {label}\")\n",
        "\n",
        "    split_labels = np.array(split_labels_normalized)\n",
        "\n",
        "    # Log data statistics for debugging\n",
        "    print(\n",
        "        f\"[{dataset_name}] Data loaded: n={len(series_data)}, range=[{series_data.min():.2e}, {series_data.max():.2e}], mean={series_data.mean():.2e}\"\n",
        "    )\n",
        "    print(\n",
        "        f\"[{dataset_name}] Splits: Train={np.sum(split_labels=='Treinamento')}, Val={np.sum(split_labels=='Validacao')}, Test={np.sum(split_labels=='Teste')}\"\n",
        "    )\n",
        "\n",
        "    # Check for suspicious outliers (values > 10 when data should be in [0,1])\n",
        "    # Remove corrupted values that are clearly data entry errors\n",
        "    outlier_threshold = (\n",
        "        10.0  # If normalized data should be [0,1], anything > 10 is corrupted\n",
        "    )\n",
        "    outlier_mask = series_data > outlier_threshold\n",
        "\n",
        "    if np.any(outlier_mask):\n",
        "        n_outliers = np.sum(outlier_mask)\n",
        "        outlier_indices = np.where(outlier_mask)[0]\n",
        "        print(\n",
        "            f\"[{dataset_name}] WARNING: Found {n_outliers} corrupted values > {outlier_threshold}\"\n",
        "        )\n",
        "        print(f\"  Outlier indices: {outlier_indices[:10]}\")\n",
        "        print(f\"  Outlier values: {series_data[outlier_mask][:10]}\")\n",
        "\n",
        "        # Replace outliers with the median of surrounding valid values\n",
        "        for idx in outlier_indices:\n",
        "            # Get surrounding values (before and after)\n",
        "            before_idx = max(0, idx - 5)\n",
        "            after_idx = min(len(series_data), idx + 6)\n",
        "            surrounding = series_data[before_idx:after_idx]\n",
        "            valid_surrounding = surrounding[surrounding <= outlier_threshold]\n",
        "\n",
        "            if len(valid_surrounding) > 0:\n",
        "                replacement = np.median(valid_surrounding)\n",
        "                series_data[idx] = replacement\n",
        "                print(\n",
        "                    f\"  Replaced index {idx} (value={series_data[idx]:.2e}) with median={replacement:.4f}\"\n",
        "                )\n",
        "            else:\n",
        "                # Fallback: use overall median of series\n",
        "                series_data[idx] = np.median(\n",
        "                    series_data[series_data <= outlier_threshold]\n",
        "                )\n",
        "\n",
        "        print(\n",
        "            f\"[{dataset_name}] Fixed! New range: [{series_data.min():.2e}, {series_data.max():.2e}]\"\n",
        "        )\n",
        "\n",
        "    return series_data, split_labels\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# SEQUENCE CREATION\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "def create_sequences_no_leakage(\n",
        "    series_data: np.ndarray, split_labels: np.ndarray, lookback: int\n",
        ") -> Tuple:\n",
        "    \"\"\"\n",
        "    Create sequences without data leakage across splits\n",
        "    - Scaler fits only on training data\n",
        "    - Sequences cannot look back across split boundaries\n",
        "    \"\"\"\n",
        "\n",
        "    # Fit scaler only on training data\n",
        "    train_mask = split_labels == \"Treinamento\"\n",
        "    train_data = series_data[train_mask]\n",
        "\n",
        "    if len(train_data) < 10:\n",
        "        raise ValueError(f\"Insufficient training data: {len(train_data)} points\")\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaler.fit(train_data.reshape(-1, 1))\n",
        "\n",
        "    # Normalize entire series using training statistics\n",
        "    series_normalized = scaler.transform(series_data.reshape(-1, 1)).ravel()\n",
        "\n",
        "    # Create sequences\n",
        "    X_train, y_train, y_train_orig = [], [], []\n",
        "    X_val, y_val, y_val_orig = [], [], []\n",
        "    X_test, y_test, y_test_orig = [], [], []\n",
        "\n",
        "    for i in range(lookback, len(series_data)):\n",
        "        sequence_norm = series_normalized[i - lookback : i]\n",
        "        target_norm = series_normalized[i]\n",
        "        target_orig = series_data[i]\n",
        "        target_split = split_labels[i]\n",
        "\n",
        "        lookback_splits = split_labels[i - lookback : i]\n",
        "\n",
        "        # Only add if entire sequence (lookback + target) is from same split\n",
        "        if target_split == \"Treinamento\" and np.all(lookback_splits == \"Treinamento\"):\n",
        "            X_train.append(sequence_norm)\n",
        "            y_train.append(target_norm)\n",
        "            y_train_orig.append(target_orig)\n",
        "\n",
        "        elif target_split == \"Validacao\" and np.all(lookback_splits == \"Validacao\"):\n",
        "            X_val.append(sequence_norm)\n",
        "            y_val.append(target_norm)\n",
        "            y_val_orig.append(target_orig)\n",
        "\n",
        "        elif target_split == \"Teste\" and np.all(lookback_splits == \"Teste\"):\n",
        "            X_test.append(sequence_norm)\n",
        "            y_test.append(target_norm)\n",
        "            y_test_orig.append(target_orig)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_train = (\n",
        "        np.array(X_train) if len(X_train) > 0 else np.array([]).reshape(0, lookback)\n",
        "    )\n",
        "    y_train = np.array(y_train) if len(y_train) > 0 else np.array([])\n",
        "    y_train_orig = np.array(y_train_orig) if len(y_train_orig) > 0 else np.array([])\n",
        "\n",
        "    X_val = np.array(X_val) if len(X_val) > 0 else np.array([]).reshape(0, lookback)\n",
        "    y_val = np.array(y_val) if len(y_val) > 0 else np.array([])\n",
        "    y_val_orig = np.array(y_val_orig) if len(y_val_orig) > 0 else np.array([])\n",
        "\n",
        "    X_test = np.array(X_test) if len(X_test) > 0 else np.array([]).reshape(0, lookback)\n",
        "    y_test = np.array(y_test) if len(y_test) > 0 else np.array([])\n",
        "    y_test_orig = np.array(y_test_orig) if len(y_test_orig) > 0 else np.array([])\n",
        "\n",
        "    if len(X_train) < 10:\n",
        "        raise ValueError(f\"Insufficient training sequences: {len(X_train)}\")\n",
        "\n",
        "    return (\n",
        "        X_train,\n",
        "        y_train,\n",
        "        X_val,\n",
        "        y_val,\n",
        "        X_test,\n",
        "        y_test,\n",
        "        y_train_orig,\n",
        "        y_val_orig,\n",
        "        y_test_orig,\n",
        "        scaler,\n",
        "    )\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# DATASET CLASS\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    \"\"\"PyTorch Dataset for time series\"\"\"\n",
        "\n",
        "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
        "        self.X = torch.FloatTensor(X)\n",
        "        self.y = torch.FloatTensor(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# LSTM MODEL\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    \"\"\"LSTM for time series forecasting\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int = 1,\n",
        "        hidden_size: int = 64,\n",
        "        num_layers: int = 1,\n",
        "        dropout: float = 0.0,\n",
        "    ):\n",
        "        super(LSTMModel, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0,\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, (h, c) = self.lstm(x)\n",
        "        out = out[:, -1, :]\n",
        "        out = self.fc(out)\n",
        "        return out.squeeze(-1)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# TRAINING\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping handler\"\"\"\n",
        "\n",
        "    def __init__(self, patience: int = 10, min_delta: float = 0.0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = float(\"inf\")\n",
        "        self.best_state = None\n",
        "        self.best_epoch = 0\n",
        "\n",
        "    def __call__(self, val_loss: float, model: nn.Module, epoch: int) -> bool:\n",
        "        \"\"\"Returns True if should stop training\"\"\"\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_state = model.state_dict().copy()\n",
        "            self.best_epoch = epoch\n",
        "            self.counter = 0\n",
        "            return False\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            return self.counter >= self.patience\n",
        "\n",
        "    def load_best_state(self, model: nn.Module):\n",
        "        \"\"\"Load best model state\"\"\"\n",
        "        if self.best_state is not None:\n",
        "            model.load_state_dict(self.best_state)\n",
        "\n",
        "\n",
        "def train_one_epoch(\n",
        "    model: nn.Module,\n",
        "    train_loader: DataLoader,\n",
        "    criterion: nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        ") -> float:\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(X_batch)\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * len(X_batch)\n",
        "\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "\n",
        "def validate_one_epoch(\n",
        "    model: nn.Module, val_loader: DataLoader, criterion: nn.Module\n",
        ") -> float:\n",
        "    \"\"\"Validate for one epoch\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            y_pred = model(X_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            total_loss += loss.item() * len(X_batch)\n",
        "\n",
        "    return total_loss / len(val_loader.dataset)\n",
        "\n",
        "\n",
        "def train_lstm(\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    config: Dict,\n",
        "    max_epochs: int = 200,\n",
        "    patience: int = 15,\n",
        ") -> Tuple[nn.Module, Dict]:\n",
        "    \"\"\"Train LSTM with early stopping\"\"\"\n",
        "    model = LSTMModel(\n",
        "        input_size=1,\n",
        "        hidden_size=config[\"hidden_size\"],\n",
        "        num_layers=config[\"num_layers\"],\n",
        "        dropout=config[\"dropout\"],\n",
        "    ).to(device)\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
        "    early_stopping = EarlyStopping(patience=patience)\n",
        "\n",
        "    history = {\"train_loss\": [], \"val_loss\": [], \"best_epoch\": 0}\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer)\n",
        "        val_loss = validate_one_epoch(model, val_loader, criterion)\n",
        "\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "\n",
        "        if early_stopping(val_loss, model, epoch + 1):\n",
        "            break\n",
        "\n",
        "    early_stopping.load_best_state(model)\n",
        "    history[\"best_epoch\"] = early_stopping.best_epoch\n",
        "\n",
        "    return model, history\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# EVALUATION\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "def evaluate_model(\n",
        "    model: nn.Module, data_loader: DataLoader\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Evaluate model and return predictions\"\"\"\n",
        "    model.eval()\n",
        "    y_true_list, y_pred_list = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_pred = model(X_batch)\n",
        "\n",
        "            y_true_list.append(y_batch.cpu().numpy())\n",
        "            y_pred_list.append(y_pred.cpu().numpy())\n",
        "\n",
        "    return np.concatenate(y_true_list), np.concatenate(y_pred_list)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# RESULTS SAVING\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "def save_results_to_csv(results_data: Dict, filename: str = \"results/lstm_results.csv\"):\n",
        "    \"\"\"Save results to CSV\"\"\"\n",
        "    os.makedirs(\n",
        "        os.path.dirname(filename) if os.path.dirname(filename) else \".\", exist_ok=True\n",
        "    )\n",
        "\n",
        "    df = pd.DataFrame([results_data])\n",
        "\n",
        "    if os.path.exists(filename):\n",
        "        df.to_csv(filename, mode=\"a\", header=False, index=False)\n",
        "    else:\n",
        "        df.to_csv(filename, mode=\"w\", header=True, index=False)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXPERIMENT PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "def run_single_experiment(\n",
        "    dataset_name: str,\n",
        "    run_num: int,\n",
        "    config: Dict,\n",
        "    series_data: np.ndarray,\n",
        "    split_labels: np.ndarray,\n",
        ") -> Dict:\n",
        "    \"\"\"Run single experiment\"\"\"\n",
        "\n",
        "    set_seed(42 + run_num)\n",
        "    # Always use DEFAULT_CONFIG for the model config\n",
        "    config = DEFAULT_CONFIG\n",
        "    lookback = config[\"lookback\"]\n",
        "\n",
        "    # Create sequences\n",
        "    (\n",
        "        X_train,\n",
        "        y_train,\n",
        "        X_val,\n",
        "        y_val,\n",
        "        X_test,\n",
        "        y_test,\n",
        "        y_train_orig,\n",
        "        y_val_orig,\n",
        "        y_test_orig,\n",
        "        scaler,\n",
        "    ) = create_sequences_no_leakage(series_data, split_labels, lookback)\n",
        "\n",
        "    # Prepare data for LSTM\n",
        "    X_train_reshaped = X_train.reshape(-1, lookback, 1)\n",
        "    X_val_reshaped = X_val.reshape(-1, lookback, 1)\n",
        "    X_test_reshaped = X_test.reshape(-1, lookback, 1)\n",
        "\n",
        "    train_dataset = TimeSeriesDataset(X_train_reshaped, y_train)\n",
        "    val_dataset = TimeSeriesDataset(X_val_reshaped, y_val)\n",
        "    test_dataset = TimeSeriesDataset(X_test_reshaped, y_test)\n",
        "\n",
        "    g = torch.Generator()\n",
        "    g.manual_seed(42 + run_num)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g,\n",
        "    )\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    train_loader_eval = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Train model\n",
        "    start_time = time.time()\n",
        "    model, history = train_lstm(\n",
        "        train_loader, val_loader, config, max_epochs=MAX_EPOCHS, patience=PATIENCE\n",
        "    )\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Get predictions and denormalize\n",
        "    _, y_pred_train_norm = evaluate_model(model, train_loader_eval)\n",
        "    _, y_pred_val_norm = evaluate_model(model, val_loader)\n",
        "    _, y_pred_test_norm = evaluate_model(model, test_loader)\n",
        "\n",
        "    y_pred_train = scaler.inverse_transform(y_pred_train_norm.reshape(-1, 1)).ravel()\n",
        "    y_pred_val = scaler.inverse_transform(y_pred_val_norm.reshape(-1, 1)).ravel()\n",
        "    y_pred_test = scaler.inverse_transform(y_pred_test_norm.reshape(-1, 1)).ravel()\n",
        "\n",
        "    # Calculate metrics on original scale\n",
        "    train_metrics = calculate_metrics(y_train_orig, y_pred_train)\n",
        "    val_metrics = calculate_metrics(y_val_orig, y_pred_val)\n",
        "    test_metrics = calculate_metrics(y_test_orig, y_pred_test)\n",
        "\n",
        "    # Prepare results\n",
        "    results = {\n",
        "        \"experiment_num\": run_num,\n",
        "        \"dataset\": dataset_name,\n",
        "        \"method\": \"LSTM\",\n",
        "        \"lookback\": lookback,\n",
        "        \"hidden_size\": config[\"hidden_size\"],\n",
        "        \"num_layers\": config[\"num_layers\"],\n",
        "        \"dropout\": config[\"dropout\"],\n",
        "        \"learning_rate\": config[\"lr\"],\n",
        "        \"best_epoch\": history[\"best_epoch\"],\n",
        "        \"training_time_sec\": training_time,\n",
        "        \"mse_train\": train_metrics[\"mse\"],\n",
        "        \"rmse_train\": train_metrics[\"rmse\"],\n",
        "        \"r2_train\": train_metrics[\"r2\"],\n",
        "        \"mse_val\": val_metrics[\"mse\"],\n",
        "        \"rmse_val\": val_metrics[\"rmse\"],\n",
        "        \"r2_val\": val_metrics[\"r2\"],\n",
        "        \"mse_test\": test_metrics[\"mse\"],\n",
        "        \"rmse_test\": test_metrics[\"rmse\"],\n",
        "        \"r2_test\": test_metrics[\"r2\"],\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def run_dataset_experiments(dataset_name: str):\n",
        "    \"\"\"Run all experiments for a single dataset\"\"\"\n",
        "\n",
        "    # Always use DEFAULT_CONFIG for the model config\n",
        "    config = DEFAULT_CONFIG\n",
        "\n",
        "    # Load data\n",
        "    series_data, split_labels = load_lstm_data_temporal(dataset_name)\n",
        "\n",
        "    # Run multiple experiments\n",
        "    dataset_results = []\n",
        "\n",
        "    for run_num in range(1, NUM_RUNS + 1):\n",
        "        try:\n",
        "            results = run_single_experiment(\n",
        "                dataset_name, run_num, config, series_data, split_labels\n",
        "            )\n",
        "            dataset_results.append(results)\n",
        "            save_results_to_csv(results)\n",
        "            print(\n",
        "                f\"{dataset_name} - Run {run_num}/{NUM_RUNS} - Test MSE: {results['mse_test']:.6e}, RMSE: {results['rmse_test']:.6e}\"\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"{dataset_name} - Run {run_num} failed: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Summary\n",
        "    if dataset_results:\n",
        "        test_mses = [r[\"mse_test\"] for r in dataset_results]\n",
        "        test_rmses = [r[\"rmse_test\"] for r in dataset_results]\n",
        "        print(f\"\\n{dataset_name} Summary:\")\n",
        "        print(f\"Test MSE:  {np.mean(test_mses):.6e} ± {np.std(test_mses):.6e}\")\n",
        "        print(f\"Test RMSE: {np.mean(test_rmses):.6e} ± {np.std(test_rmses):.6e}\\n\")\n",
        "\n",
        "    return dataset_results\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    DATASETS = [\n",
        "        \"CARSALES\",\n",
        "        \"Electricity\",\n",
        "        \"GAS\",\n",
        "        \"LAKEERIE\",\n",
        "        \"Nordic\",\n",
        "        \"PIGS\",\n",
        "        \"POLLUTION\",\n",
        "        \"REDWINE\",\n",
        "        \"SUNSPOT\",\n",
        "        \"B1H\",\n",
        "    ]\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Starting LSTM Experiments\")\n",
        "    print(f\"Datasets: {len(DATASETS)}\")\n",
        "    print(f\"Runs per dataset: {NUM_RUNS}\")\n",
        "    print(f\"Max epochs: {MAX_EPOCHS} (patience={PATIENCE})\")\n",
        "    print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for dataset_name in DATASETS:\n",
        "        print(f\"\\n{'#'*60}\")\n",
        "        print(f\"DATASET: {dataset_name}\")\n",
        "        print(f\"{'#'*60}\")\n",
        "\n",
        "        results = run_dataset_experiments(dataset_name)\n",
        "        all_results.extend(results)\n",
        "\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"ALL EXPERIMENTS COMPLETED!\")\n",
        "    print(f\"Total successful runs: {len(all_results)}\")\n",
        "    print(f\"Results saved to: results/lstm_results.csv\")\n",
        "    print(f\"{'#'*60}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
