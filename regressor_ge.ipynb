{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'PonyGE2' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/PonyGE/PonyGE2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!cd PonyGE2/ && git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: numpy in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.24.1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip installs\n",
    "\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sewar in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sewar) (1.24.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sewar) (1.10.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sewar) (9.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install sewar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "experiment = \"regression\"\n",
    "\n",
    "shutil.copy(f\"./fitness/{experiment}.py\", \"./PonyGE2/src/fitness/\")\n",
    "!cd ./PonyGE2/src && python ponyge.py --parameters ../../parameters/{experiment}.txt\n",
    "os.remove(f\"./PonyGE2/src/fitness/{experiment}.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sewar.full_ref import mse\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "captured_str = str(captured).split('\\n')\n",
    "for line in captured_str:\n",
    "    if \"Phenotype: \" in line:\n",
    "        phenotype = line.replace(\"Phenotype: \", \"\")\n",
    "    elif \"DATASET_NAME\" in line:\n",
    "        dataset_name = line.replace(\"DATASET_NAME: \", \"\")\n",
    "\n",
    "dataset_path = './datasets/data.xlsx'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extremeVal(reference, val):\n",
    "    if (val > 1e2*reference) or (val < -1e2*reference):\n",
    "        return 0\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "def load_data():\n",
    "    wb = load_workbook(dataset_path)\n",
    "    dataset_name = [\"CARSALES\", \"LAKEERIE\", \"GAS\", \"Electricity\",\n",
    "                    \"PIGS\", \"POLLUTION\", \"REDWINE\", \"SUNSPOT\", \"Nordic\", \"B1H\"]\n",
    "    dataset = {}\n",
    "    for name in dataset_name:\n",
    "\n",
    "        ws = wb[name]\n",
    "        columns = [ws[\"A\"], ws[\"B\"], ws[\"C\"],\n",
    "                   ws[\"D\"], ws[\"E\"], ws[\"F\"], ws[\"G\"]]\n",
    "\n",
    "        sheet = [[] for _ in range(len(columns[0]))]\n",
    "\n",
    "        for c in columns:\n",
    "            for index, item in enumerate(c):\n",
    "                sheet[index].append(item.value)\n",
    "\n",
    "        sheet = np.array(sheet)\n",
    "        dataset[name] = {\"raw\": sheet}\n",
    "\n",
    "    for name, _ in dataset.items():\n",
    "        sheet = dataset[name][\"raw\"]\n",
    "\n",
    "        dataset[name][\"series\"] = {\n",
    "            \"treino\": [], \"teste\": [], \"validacao\": []}\n",
    "        dataset[name][\"arima\"] = {\n",
    "            \"treino\": [], \"teste\": [], \"validacao\": []}\n",
    "        dataset[name][\"mlp\"] = {\"treino\": [], \"teste\": [], \"validacao\": []}\n",
    "        dataset[name][\"svr\"] = {\"treino\": [], \"teste\": [], \"validacao\": []}\n",
    "        dataset[name][\"rbf\"] = {\"treino\": [], \"teste\": [], \"validacao\": []}\n",
    "\n",
    "        for row in sheet[1:]:\n",
    "            split_type = row[2]\n",
    "            if row[4] == None:\n",
    "                continue\n",
    "            key = None\n",
    "            if split_type == \"Teste\":\n",
    "                key = \"teste\"\n",
    "            elif split_type == \"Validacao\":\n",
    "                key = \"validacao\"\n",
    "            elif split_type == \"Treinamento\":\n",
    "                key = \"treino\"\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            dataset[name][\"series\"][key].append(float(row[1]))\n",
    "            dataset[name][\"arima\"][key] .append(float(row[3]))\n",
    "            dataset[name][\"mlp\"][key]   .append(float(row[4]))\n",
    "            dataset[name][\"svr\"][key]   .append(float(row[5]))\n",
    "            dataset[name][\"rbf\"][key]   .append(float(row[6]))\n",
    "\n",
    "        for type_data in [\"teste\", \"treino\", \"validacao\"]:\n",
    "            dataset[name][\"series\"][type_data] = np.array(\n",
    "                dataset[name][\"series\"][type_data])\n",
    "            dataset[name][\"arima\"][type_data] = np.array(\n",
    "                dataset[name][\"arima\"][type_data])\n",
    "            dataset[name][\"mlp\"][type_data] = np.array(\n",
    "                dataset[name][\"mlp\"][type_data])\n",
    "            dataset[name][\"svr\"][type_data] = np.array(\n",
    "                dataset[name][\"svr\"][type_data])\n",
    "            dataset[name][\"rbf\"][type_data] = np.array(\n",
    "                dataset[name][\"rbf\"][type_data])\n",
    "\n",
    "        fixExtreme = np.vectorize(extremeVal)\n",
    "\n",
    "    for name in dataset.keys():\n",
    "        reference = np.max(dataset[name][\"series\"][\"treino\"])\n",
    "\n",
    "        for type_data in [\"teste\", \"treino\", \"validacao\"]:\n",
    "            dataset[name][\"mlp\"][type_data] = fixExtreme(\n",
    "                reference, dataset[name][\"mlp\"][type_data])\n",
    "            dataset[name][\"svr\"][type_data] = fixExtreme(\n",
    "                reference, dataset[name][\"svr\"][type_data])\n",
    "            dataset[name][\"rbf\"][type_data] = fixExtreme(\n",
    "                reference, dataset[name][\"rbf\"][type_data])\n",
    "            dataset[name][\"arima\"][type_data] = fixExtreme(\n",
    "                reference, dataset[name][\"arima\"][type_data])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def build_model(phenotype):\n",
    "    model = {\"linear\": {}, \"nlinear\": {}}\n",
    "\n",
    "    linear, nlinear = phenotype.split(';')\n",
    "\n",
    "    weight, linear_model = linear.split(':')\n",
    "    model[\"linear\"][linear_model] = float(weight)\n",
    "\n",
    "    nlinear_parts = nlinear.split(',')\n",
    "\n",
    "    for i in range(len(nlinear_parts)):\n",
    "        weight, nlinear_model = nlinear_parts[i].split(':')\n",
    "        model[\"nlinear\"][nlinear_model] = float(weight)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_mse(dataset, phenotype, series_name):\n",
    "    model = build_model(phenotype)\n",
    "    name = list(model[\"linear\"].keys())[0]\n",
    "    predict = np.zeros(len(dataset[dataset_name][name][series_name]))\n",
    "\n",
    "    for key, val in model[\"linear\"].items():\n",
    "        predict += dataset[dataset_name][key][series_name] * val\n",
    "\n",
    "    for key, val in model[\"nlinear\"].items():\n",
    "\n",
    "        predict += dataset[dataset_name][key][series_name] * val\n",
    "\n",
    "    return mse(dataset[dataset_name][\"series\"][series_name], predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: B1H\n",
      "Fenótipo:   1:arima;0.20:rbf,1:svr\n",
      "Fitness treino: 1.460e-03\n",
      "Fitness teste: 4.433e-04\n",
      "Fitness validacao: 3.062e-04\n"
     ]
    }
   ],
   "source": [
    "dataset = load_data()\n",
    "print(f'Dataset: {dataset_name}')\n",
    "print(f'Fenótipo: {phenotype}')\n",
    "print('Fitness treino:', f\"{predict_mse(dataset, phenotype, 'treino'):.3e}\")\n",
    "print('Fitness teste:', f\"{predict_mse(dataset, phenotype, 'teste'):.3e}\")\n",
    "print('Fitness validacao:', f\"{predict_mse(dataset, phenotype, 'validacao'):.3e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec24db49983a949fb72ed67dd1ffbda33d167907641147950d83ba6b0bf33f37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
