{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'PonyGE2' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/PonyGE/PonyGE2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!cd PonyGE2/ && git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: numpy in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.24.1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip installs\n",
    "\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sewar in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sewar) (1.24.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sewar) (1.10.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sewar) (9.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install sewar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "experiment = \"regression\"\n",
    "\n",
    "shutil.copy(f\"./fitness/{experiment}.py\", \"./PonyGE2/src/fitness/\")\n",
    "!cd ./PonyGE2/src && python ponyge.py --parameters ../../parameters/{experiment}.txt\n",
    "os.remove(f\"./PonyGE2/src/fitness/{experiment}.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sewar.full_ref import mse\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "captured_str = str(captured).split('\\n')\n",
    "for line in captured_str:\n",
    "    if \"Phenotype: \" in line:\n",
    "        phenotype = line.replace(\"Phenotype: \", \"\")\n",
    "    elif \"DATASET_NAME\" in line:\n",
    "        dataset_name = line.replace(\"DATASET_NAME: \", \"\")\n",
    "\n",
    "dataset_path = './datasets/data.xlsx'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def extremeVal(reference, val):\n",
    "    if (val > 1e2*reference) or (val < -1e2*reference):\n",
    "        return 0\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "def load_data():\n",
    "    wb = load_workbook(dataset_path)\n",
    "    dataset_name = [\"CARSALES\", \"LAKEERIE\", \"GAS\", \"Electricity\",\n",
    "                    \"PIGS\", \"POLLUTION\", \"REDWINE\", \"SUNSPOT\", \"Nordic\", \"B1H\"]\n",
    "    dataset = {}\n",
    "    for name in dataset_name:\n",
    "\n",
    "        ws = wb[name]\n",
    "        columns = [ws[\"A\"], ws[\"B\"], ws[\"C\"],\n",
    "                   ws[\"D\"], ws[\"E\"], ws[\"F\"], ws[\"G\"]]\n",
    "\n",
    "        sheet = [[] for _ in range(len(columns[0]))]\n",
    "\n",
    "        for c in columns:\n",
    "            for index, item in enumerate(c):\n",
    "                sheet[index].append(item.value)\n",
    "\n",
    "        sheet = np.array(sheet)\n",
    "        dataset[name] = {\"raw\": sheet}\n",
    "\n",
    "    for name, _ in dataset.items():\n",
    "        sheet = dataset[name][\"raw\"]\n",
    "\n",
    "        dataset[name][\"series\"] = {\n",
    "            \"treino\": [], \"teste\": [], \"validacao\": []}\n",
    "        dataset[name][\"arima\"] = {\n",
    "            \"treino\": [], \"teste\": [], \"validacao\": []}\n",
    "        dataset[name][\"mlp\"] = {\"treino\": [], \"teste\": [], \"validacao\": []}\n",
    "        dataset[name][\"svr\"] = {\"treino\": [], \"teste\": [], \"validacao\": []}\n",
    "        dataset[name][\"rbf\"] = {\"treino\": [], \"teste\": [], \"validacao\": []}\n",
    "\n",
    "        for row in sheet[1:]:\n",
    "            split_type = row[2]\n",
    "            if row[4] == None:\n",
    "                continue\n",
    "            key = None\n",
    "            if split_type == \"Teste\":\n",
    "                key = \"teste\"\n",
    "            elif split_type == \"Validacao\":\n",
    "                key = \"validacao\"\n",
    "            elif split_type == \"Treinamento\":\n",
    "                key = \"treino\"\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            dataset[name][\"series\"][key].append(float(row[1]))\n",
    "            dataset[name][\"arima\"][key] .append(float(row[3]))\n",
    "            dataset[name][\"mlp\"][key]   .append(float(row[4]))\n",
    "            dataset[name][\"svr\"][key]   .append(float(row[5]))\n",
    "            dataset[name][\"rbf\"][key]   .append(float(row[6]))\n",
    "\n",
    "        for type_data in [\"teste\", \"treino\", \"validacao\"]:\n",
    "            dataset[name][\"series\"][type_data] = np.array(\n",
    "                dataset[name][\"series\"][type_data])\n",
    "            dataset[name][\"arima\"][type_data] = np.array(\n",
    "                dataset[name][\"arima\"][type_data])\n",
    "            dataset[name][\"mlp\"][type_data] = np.array(\n",
    "                dataset[name][\"mlp\"][type_data])\n",
    "            dataset[name][\"svr\"][type_data] = np.array(\n",
    "                dataset[name][\"svr\"][type_data])\n",
    "            dataset[name][\"rbf\"][type_data] = np.array(\n",
    "                dataset[name][\"rbf\"][type_data])\n",
    "\n",
    "        fixExtreme = np.vectorize(extremeVal)\n",
    "\n",
    "    for name in dataset.keys():\n",
    "        reference = np.max(dataset[name][\"series\"][\"treino\"])\n",
    "\n",
    "        for type_data in [\"teste\", \"treino\", \"validacao\"]:\n",
    "            dataset[name][\"mlp\"][type_data] = fixExtreme(\n",
    "                reference, dataset[name][\"mlp\"][type_data])\n",
    "            dataset[name][\"svr\"][type_data] = fixExtreme(\n",
    "                reference, dataset[name][\"svr\"][type_data])\n",
    "            dataset[name][\"rbf\"][type_data] = fixExtreme(\n",
    "                reference, dataset[name][\"rbf\"][type_data])\n",
    "            dataset[name][\"arima\"][type_data] = fixExtreme(\n",
    "                reference, dataset[name][\"arima\"][type_data])\n",
    "\n",
    "    return dataset[name]\n",
    "\n",
    "def build_model(phenotype):\n",
    "    model = {\"linear\": {}, \"nlinear\": {}}\n",
    "\n",
    "    linear, nlinear = phenotype.split(';')\n",
    "\n",
    "    weight, linear_model = linear.split(':')\n",
    "    model[\"linear\"][linear_model] = float(weight)\n",
    "\n",
    "    nlinear_parts = nlinear.split(',')\n",
    "\n",
    "    for i in range(len(nlinear_parts)):\n",
    "        weight, nlinear_model = nlinear_parts[i].split(':')\n",
    "        model[\"nlinear\"][nlinear_model] = float(weight)\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_mse(dataset, model, series_name):\n",
    "    predict = dataset[\"series\"][series_name]\n",
    "    window_size = 1\n",
    "    X_train = apply_window(dataset,\n",
    "        window_size, series_name, model_names=model[\"nlinear\"].keys())\n",
    "    kernel = []\n",
    "    for _ in range(window_size):\n",
    "        for _, val in model[\"linear\"].items():\n",
    "            kernel.append(val)\n",
    "        for _, val in model[\"nlinear\"].items():\n",
    "            kernel.append(val)\n",
    "    return mse(create_prediction(X_train, np.reshape(kernel, (1, -1))), predict)\n",
    "\n",
    "def apply_window(dataset, window_size, data_type, model_names=None):\n",
    "    size_pred = len(dataset[\"series\"][data_type])\n",
    "    new_data = []\n",
    "    for w in range(window_size):\n",
    "        linear = np.concatenate(\n",
    "            [np.zeros(w), dataset[\"arima\"][data_type]])\n",
    "        linear = linear[:size_pred]\n",
    "        row = np.array(linear)\n",
    "        for model_name in model_names:\n",
    "            nonlinear = np.concatenate(\n",
    "                [np.zeros(w), dataset[model_name][data_type]])\n",
    "            nonlinear = nonlinear[:size_pred]\n",
    "            row = np.column_stack([row, nonlinear])\n",
    "        if len(new_data) == 0:\n",
    "            new_data = row\n",
    "        else:\n",
    "            new_data = np.column_stack([new_data, row])\n",
    "    return np.array(new_data)\n",
    "\n",
    "def create_prediction(X, kernel):\n",
    "    X = torch.tensor(np.expand_dims(X, axis=(0, 1))).float()\n",
    "    kernel = torch.tensor(np.expand_dims(kernel, axis=(0, 1))).float()\n",
    "    X.to(device)\n",
    "    kernel.to(device)\n",
    "    result = F.conv2d(X, kernel)\n",
    "    return result.numpy().squeeze().astype(\"f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: B1H\n",
      "Fenótipo:   000.096:arima;1.2:mlp\n",
      "Fitness treino: 2.157e-02\n",
      "Fitness teste: 2.102e-02\n",
      "Fitness validacao: 8.845e-03\n"
     ]
    }
   ],
   "source": [
    "dataset = load_data()\n",
    "model = build_model(phenotype)\n",
    "print(f'Dataset: {dataset_name}')\n",
    "print(f'Fenótipo: {phenotype}')\n",
    "print('Fitness treino:', f\"{predict_mse(dataset, model, 'treino'):.3e}\")\n",
    "print('Fitness teste:', f\"{predict_mse(dataset, model, 'teste'):.3e}\")\n",
    "print('Fitness validacao:', f\"{predict_mse(dataset, model, 'validacao'):.3e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec24db49983a949fb72ed67dd1ffbda33d167907641147950d83ba6b0bf33f37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
