{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'PonyGE2' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/PonyGE/PonyGE2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!cd PonyGE2/ && git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: numpy in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.24.1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip installs\n",
    "\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sewar in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sewar) (1.24.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sewar) (1.10.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sewar) (9.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install sewar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\hsabi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start:\t 2023-05-04 19:34:43.549463 \n",
      "\n",
      "DATASET_NAME: B1H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\hsabi\\Projects\\AIBox\\RegressorGE\\PonyGE2\\src\\utilities\\algorithm\\NSGA2.py\", line 291, in __init__\n",
      "    self.n_objectives = params['FITNESS_FUNCTION'].num_obj\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'regression' object has no attribute 'num_obj'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\hsabi\\Projects\\AIBox\\RegressorGE\\PonyGE2\\src\\ponyge.py\", line 31, in <module>\n",
      "    mane()\n",
      "  File \"c:\\Users\\hsabi\\Projects\\AIBox\\RegressorGE\\PonyGE2\\src\\ponyge.py\", line 24, in mane\n",
      "    individuals = params['SEARCH_LOOP']()\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hsabi\\Projects\\AIBox\\RegressorGE\\PonyGE2\\src\\algorithm\\search_loop.py\", line 32, in search_loop\n",
      "    get_stats(individuals)\n",
      "  File \"c:\\Users\\hsabi\\Projects\\AIBox\\RegressorGE\\PonyGE2\\src\\stats\\stats.py\", line 64, in get_stats\n",
      "    get_moo_stats(individuals, end)\n",
      "  File \"c:\\Users\\hsabi\\Projects\\AIBox\\RegressorGE\\PonyGE2\\src\\stats\\stats.py\", line 164, in get_moo_stats\n",
      "    pareto = compute_pareto_metrics(individuals)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hsabi\\Projects\\AIBox\\RegressorGE\\PonyGE2\\src\\utilities\\algorithm\\NSGA2.py\", line 17, in compute_pareto_metrics\n",
      "    pareto = sort_non_dominated(population)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hsabi\\Projects\\AIBox\\RegressorGE\\PonyGE2\\src\\utilities\\algorithm\\NSGA2.py\", line 44, in sort_non_dominated\n",
      "    pareto = ParetoInfo()\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hsabi\\Projects\\AIBox\\RegressorGE\\PonyGE2\\src\\utilities\\algorithm\\NSGA2.py\", line 300, in __init__\n",
      "    raise Exception(s)\n",
      "Exception: utilities.algorithm.NSGA2\n",
      "Error: Specified fitness function does not have 'num_obj' attribute.\n",
      "       If using multiple objective optimisation, ensure fitness.base_ff_classes.base_moo_ff is implemented.\n",
      "       See README documentation for more information.\n"
     ]
    }
   ],
   "source": [
    "%%capture captured\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "experiment = \"regression\"\n",
    "\n",
    "shutil.copy(f\"./fitness/{experiment}.py\", \"./PonyGE2/src/fitness/\")\n",
    "!cd ./PonyGE2/src && python ponyge.py --parameters ../../parameters/{experiment}.txt\n",
    "os.remove(f\"./PonyGE2/src/fitness/{experiment}.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sewar.full_ref import mse\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "captured_str = str(captured).split('\\n')\n",
    "for line in captured_str:\n",
    "    if \"Phenotype: \" in line:\n",
    "        phenotype = line.replace(\"Phenotype: \", \"\")\n",
    "    elif \"DATASET_NAME\" in line:\n",
    "        dataset_name = line.replace(\"DATASET_NAME: \", \"\")\n",
    "\n",
    "dataset_path = './datasets/data.xlsx'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extremeVal(reference, val):\n",
    "    if (val > 1e2*reference) or (val < -1e2*reference):\n",
    "        return 0\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "def load_data():\n",
    "    wb = load_workbook(dataset_path)\n",
    "    dataset_name = [\"CARSALES\", \"LAKEERIE\", \"GAS\", \"Electricity\",\n",
    "                    \"PIGS\", \"POLLUTION\", \"REDWINE\", \"SUNSPOT\", \"Nordic\", \"B1H\"]\n",
    "    dataset = {}\n",
    "    for name in dataset_name:\n",
    "\n",
    "        ws = wb[name]\n",
    "        columns = [ws[\"A\"], ws[\"B\"], ws[\"C\"],\n",
    "                   ws[\"D\"], ws[\"E\"], ws[\"F\"], ws[\"G\"]]\n",
    "\n",
    "        sheet = [[] for _ in range(len(columns[0]))]\n",
    "\n",
    "        for c in columns:\n",
    "            for index, item in enumerate(c):\n",
    "                sheet[index].append(item.value)\n",
    "\n",
    "        sheet = np.array(sheet)\n",
    "        dataset[name] = {\"raw\": sheet}\n",
    "\n",
    "    for name, _ in dataset.items():\n",
    "        sheet = dataset[name][\"raw\"]\n",
    "\n",
    "        dataset[name][\"series\"] = {\n",
    "            \"treino\": [], \"teste\": [], \"validacao\": []}\n",
    "        dataset[name][\"arima\"] = {\n",
    "            \"treino\": [], \"teste\": [], \"validacao\": []}\n",
    "        dataset[name][\"mlp\"] = {\"treino\": [], \"teste\": [], \"validacao\": []}\n",
    "        dataset[name][\"svr\"] = {\"treino\": [], \"teste\": [], \"validacao\": []}\n",
    "        dataset[name][\"rbf\"] = {\"treino\": [], \"teste\": [], \"validacao\": []}\n",
    "\n",
    "        for row in sheet[1:]:\n",
    "            split_type = row[2]\n",
    "            if row[4] == None:\n",
    "                continue\n",
    "            key = None\n",
    "            if split_type == \"Teste\":\n",
    "                key = \"teste\"\n",
    "            elif split_type == \"Validacao\":\n",
    "                key = \"validacao\"\n",
    "            elif split_type == \"Treinamento\":\n",
    "                key = \"treino\"\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            dataset[name][\"series\"][key].append(float(row[1]))\n",
    "            dataset[name][\"arima\"][key] .append(float(row[3]))\n",
    "            dataset[name][\"mlp\"][key]   .append(float(row[4]))\n",
    "            dataset[name][\"svr\"][key]   .append(float(row[5]))\n",
    "            dataset[name][\"rbf\"][key]   .append(float(row[6]))\n",
    "\n",
    "        for type_data in [\"teste\", \"treino\", \"validacao\"]:\n",
    "            dataset[name][\"series\"][type_data] = np.array(\n",
    "                dataset[name][\"series\"][type_data])\n",
    "            dataset[name][\"arima\"][type_data] = np.array(\n",
    "                dataset[name][\"arima\"][type_data])\n",
    "            dataset[name][\"mlp\"][type_data] = np.array(\n",
    "                dataset[name][\"mlp\"][type_data])\n",
    "            dataset[name][\"svr\"][type_data] = np.array(\n",
    "                dataset[name][\"svr\"][type_data])\n",
    "            dataset[name][\"rbf\"][type_data] = np.array(\n",
    "                dataset[name][\"rbf\"][type_data])\n",
    "\n",
    "        fixExtreme = np.vectorize(extremeVal)\n",
    "\n",
    "    for name in dataset.keys():\n",
    "        reference = np.max(dataset[name][\"series\"][\"treino\"])\n",
    "\n",
    "        for type_data in [\"teste\", \"treino\", \"validacao\"]:\n",
    "            dataset[name][\"mlp\"][type_data] = fixExtreme(\n",
    "                reference, dataset[name][\"mlp\"][type_data])\n",
    "            dataset[name][\"svr\"][type_data] = fixExtreme(\n",
    "                reference, dataset[name][\"svr\"][type_data])\n",
    "            dataset[name][\"rbf\"][type_data] = fixExtreme(\n",
    "                reference, dataset[name][\"rbf\"][type_data])\n",
    "            dataset[name][\"arima\"][type_data] = fixExtreme(\n",
    "                reference, dataset[name][\"arima\"][type_data])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def build_model(phenotype):\n",
    "    model = {\"linear\": {}, \"nlinear\": {}}\n",
    "\n",
    "    linear, nlinear = phenotype.split(';')\n",
    "\n",
    "    weight, linear_model = linear.split(':')\n",
    "    model[\"linear\"][linear_model] = float(weight)\n",
    "\n",
    "    nlinear_parts = nlinear.split(',')\n",
    "\n",
    "    for i in range(len(nlinear_parts)):\n",
    "        weight, nlinear_model = nlinear_parts[i].split(':')\n",
    "        model[\"nlinear\"][nlinear_model] = float(weight)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_mse(dataset, phenotype, series_name):\n",
    "    model = build_model(phenotype)\n",
    "    name = list(model[\"linear\"].keys())[0]\n",
    "    predict = np.zeros(len(dataset[dataset_name][name][series_name]))\n",
    "\n",
    "    for key, val in model[\"linear\"].items():\n",
    "        predict += dataset[dataset_name][key][series_name] * val\n",
    "\n",
    "    for key, val in model[\"nlinear\"].items():\n",
    "\n",
    "        predict += dataset[dataset_name][key][series_name] * val\n",
    "\n",
    "    return mse(dataset[dataset_name][\"series\"][series_name], predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: B1H\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'phenotype' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset \u001b[39m=\u001b[39m load_data()\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDataset: \u001b[39m\u001b[39m{\u001b[39;00mdataset_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFenótipo: \u001b[39m\u001b[39m{\u001b[39;00mphenotype\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFitness treino:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpredict_mse(dataset,\u001b[39m \u001b[39mphenotype,\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtreino\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m:\u001b[39;00m\u001b[39m.3e\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFitness teste:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpredict_mse(dataset,\u001b[39m \u001b[39mphenotype,\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mteste\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m:\u001b[39;00m\u001b[39m.3e\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'phenotype' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = load_data()\n",
    "print(f'Dataset: {dataset_name}')\n",
    "print(f'Fenótipo: {phenotype}')\n",
    "print('Fitness treino:', f\"{predict_mse(dataset, phenotype, 'treino'):.3e}\")\n",
    "print('Fitness teste:', f\"{predict_mse(dataset, phenotype, 'teste'):.3e}\")\n",
    "print('Fitness validacao:', f\"{predict_mse(dataset, phenotype, 'validacao'):.3e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec24db49983a949fb72ed67dd1ffbda33d167907641147950d83ba6b0bf33f37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
